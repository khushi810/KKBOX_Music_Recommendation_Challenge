{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbuDdrAI-Kqz"
   },
   "source": [
    "# KKBOX's Music Recommendation Challange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyEa2rJg-TiG"
   },
   "outputs": [],
   "source": [
    "# Importing basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import time\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EXbyMD-U-ZX5"
   },
   "source": [
    "## Final Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CV8iKcfl-cxV"
   },
   "source": [
    "- As we did EDA and FE and apply various ML and DL models on our data points.\n",
    "- We will define two final functions for pipline. \n",
    "- First function will take the extracted features and will apply best model on top of it and return the prediction label, either user will listen the song or not.\n",
    "- Second function will take features and corresponding labels and will return metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ENWKprM_HW1"
   },
   "outputs": [],
   "source": [
    "tr_data = pd.read_csv('/content/drive/My Drive/CS-1/tr_data.csv')\n",
    "val_data = pd.read_csv('/content/drive/My Drive/CS-1/val_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPFO290G-Vv7"
   },
   "outputs": [],
   "source": [
    "def function_1(data_point, best_model):\n",
    "  '''This function will take features and predict the label using best model'''\n",
    "  label = best_model.predict(data_point)\n",
    "  print('The label is : ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Z-yL1TO-VzK"
   },
   "outputs": [],
   "source": [
    "def function_2(data_point, label, best_model):\n",
    "  '''This function will calculate metric for given input features'''\n",
    "  predicted_label = best_model.predict(data_point)\n",
    "  auc = roc_auc_score(label, predicted_label)\n",
    "  print('AUC is : ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hY8iaLcr-V1y"
   },
   "outputs": [],
   "source": [
    "# sample validation data point for function-1  and function-2\n",
    "data_point = val_data.iloc[1].drop(['target'])\n",
    "label = np.array(val_data.iloc[1]['target'])\n",
    "# load model\n",
    "best_model = joblib.load('/content/drive/My Drive/CS-1/Data/lgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K9IhPTql-2be",
    "outputId": "8c30f0b5-aaa9-4cb8-a30d-b61a4124c5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is : [1.0]\n"
     ]
    }
   ],
   "source": [
    "function_1(data_point, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kn6PuCJ-2k0"
   },
   "outputs": [],
   "source": [
    "function_2(data_point, label, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wP8aAlm0Aetk"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iikXKsvMAY-x"
   },
   "source": [
    "-> Future steps\n",
    "- Due to RAM limitations we have taken less amount of data.\n",
    "- If we use whole data we can get better results.\n",
    "- Deep learning requires more data to get good results.\n",
    "- By tweaking parameters on large data points we can achieve better results.\n",
    "- We can also think of more feature extraction."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vaghanikhushali17@gmail.com_29_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
